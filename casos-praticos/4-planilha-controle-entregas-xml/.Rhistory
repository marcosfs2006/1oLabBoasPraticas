wdoc <- read_docx("figuras-tabelas.docx")
wdoc %>% styles_info(wdoc)
wdoc %>% styles_info()
my_doc <- my_doc %>%
body_add_flextable(head(iris))
wdoc <- wdocc %>%
body_add_flextable(head(iris))
wdoc <- wdoc %>%
body_add_flextable(head(iris))
wdoc <- wdoc %>%
body_add_flextable(flextable(head(iris)))
setwd("I:\\___Auditoria de Acompanhamento\\RMarkdown word reports\\Testes_Gerar_Word")
# Imprime o documento modificado
print(wdoc, target = "Meu_documento.docx")
knitr::opts_chunk$set(echo = TRUE, include = FALSE)
library(knitr)
# Ideia: Instalara versão nova do pandoc. Alterar a variável RSTUDIO_PANDOC para o novo pandoc
#
#Sys.getenv(NEW_PANDOC="")
#"RSTUDIO_PANDOC"
#$RSTUDIO_USER_IDENTITY
#[1] "Marcos"
wdoc <- read_docx("figuras-tabelas.docx")
wdoc <- wdoc %>%
cursor_reach(keyword = "Tabela 1") %>%
body_add_flextable(theme_vanilla(flextable(head(iris))))
# Imprime o documento modificado
print(wdoc, target = "Meu_documento2.docx")
library(knitr)
library(flextable)
library(officer)
library(magrittr)
library(tables)
library(kableExtra)
#library(htmlTable)
knitr::opts_chunk$set(echo = TRUE, include = FALSE)
Sys.getenv("RSTUDIO_USER_IDENTITY")
old_identity <- Sys.getenv("RSTUDIO_USER_IDENTITY")
old_identity
options()
Sys.setenv(RSTUDIO_USER_IDENTITY = "Luluka")
Sys.getenv("RSTUDIO_USER_IDENTITY")
Sys.setenv(RSTUDIO_USER_IDENTITY = old_identity)
Sys.getenv("RSTUDIO_USER_IDENTITY")
Sys.getenv("RSTUDIO_PANDOC")
Sys.getenv("RSTUDIO_PANDOC")
pandoc_version()
rmarkdown::pandoc_available()
rmarkdown::pandoc_version()
Sys.getenv("RSTUDIO_PANDOC")
Sys.getenv("PATH")
rmarkdown::pandoc_version()
rmarkdown::pandoc_version()
knit_print
flextable::knit_print
rmarkdown::pandoc_version()
3*(0.75^2)*0.25
4/5
knitr::opts_chunk$set(echo = TRUE)
# n = 8; p = 0.2, k = 1000
set.seed(0)
successes <- rbinom(n=8, size=1000, p=0.2)
length(successes)
# n = 8; p = 0.2, k = 1000
set.seed(0)
successes <- rbinom(n=1000, size=8, p=0.2)
length(successes)
# Questão 9
hist(successes)
binom_draws <-as_tibble(data.frame(successes))
library(dplyr)
binom_draws <-as_tibble(data.frame(successes))
View(binom_draws)
library(ggplot2)
estimated_pf <- binom_draws %>%
group_by(successes) %>%
summarise(n=n())%>%
mutate(freq = n / sum(n))
ggplot(estimated_pf, aes(x=successes, y=freq)) +
geom_col() +
ylab("Estimated Density")
my_binom <- as_tibble(list(x=0:n,
prob=dbinom(0:n, n, p)))
n <- 8
p <- 0.2
my_binom <- as_tibble(list(x=0:n,
prob=dbinom(0:n, n, p)))
my_binom
# Plot the coputed theoretical density.
ggplot(my_binom,aes(x=x, y=prob)) +
geom_col() +
ylab("Anaytical Density")
class(my_binom)
calculated_cdf <- my_binom %>%
mutate(cdf = cumsum(prob))
# Plot the computed cdf
ggplot(calculated_cdf, aes(x=x, y=cdf)) +
geom_step() +
ylab("CDF")
2557.97-451.87-119.50-120.66-72
1365.63-99-99-89.86
1793.94+1077.77
0.3*0.5+0.2*0.1+0.2*0.2+0.1*0.1+0.2*0.1
0.85*0.01
(0.85*0.01)+(0.05*0.99)
0.0085/0.058
0.94*0.01
(0.94*0.01)+(0.04*0.99)
0.0094/0.049
0.94*0.04
mean(rbinom(1000, 8, 1))
sd(rbinom(1000, 8, 1))
sd(binom_draws)
sd(binom_draws$successes)
1-0.019
0.99*0.019
(0.99*0.019)/(0.99*0.019+0.05*0.981)
1-0.27
(0.99*0.27)/(0.99*0.27+0.05*0.73)
dbinom(7, 10, 0.65)
1-0.65
0.65^7*0.35^3
0.65^7*0.35^3*120
pbinom(7, 10, 0.65, lower.tail = TRUE)
pbinom(7, 10, 0.65)
pbinom(6, 10, 0.65, lower.tail = FALSE)
pbinom(5, 10, 0.65, lower.tail = FALSE)
0.01*0.85+0.99*0.05
0.01*0.94+0.99*0.04
0.8*0.5
0.4*0.8+0.6*0.2
0.4*0.8+0.5*0.2
Sys.getenv("RSTUDIO_PANDOC")
library(knitr)
library(flextable)
library(officer)
library(magrittr)
library(rmarkdown)
knitr::opts_chunk$set(echo = TRUE, include = FALSE)
knitr::opts_knit$set(rmarkdown.pandoc.to = "docx")
#old_pandoc_dir <- Sys.getenv("RSTUDIO_PANDOC")
#Sys.setenv("RSTUDIO_PANDOC" = "C:/pandoc-2.1.1") - .Rprofile
paste(
"```{=openxml}",
docx_str.regulartable(tab_flex),
"```",
sep = "\n")
Sys.getenv("RSTUDIO_PANDOC")
Sys.getenv("RSTUDIO_PANDOC")
Sys.getenv("RSTUDIO_PANDOC")
#old_pandoc_dir <- Sys.getenv("RSTUDIO_PANDOC")
Sys.setenv("RSTUDIO_PANDOC" = "C:/pandoc-2.1.1")
Sys.getenv("RSTUDIO_PANDOC")
xx <- read.delim2(textConnection(
Banana | Feijão | Angu
142    | 175    | 148
xx <- read.delim2(textConnection(
Banana | Feijão | Angu
142    | 175    | 148
xx <- read.delim2(textConnection(
Banana | Feijão | Angu \n
xx <- read.delim2(textConnection(
Banana | Feijão | Angu
142    | 175    | 148
xx <- read.delim2(textConnection(
Banana | Feijão | Angu
142    | 175    | 148
xx <- read.delim2(textConnection(
Banana | Feijão | Angu |
142    | 175    | 148  |
136    | 177    | 156  |
166    | 12     | 76   |), sep="|", header=T)
xx <- read.delim2(textConnection(
Banana | Feijão | Angu |
142    | 175    | 148  |
136    | 177    | 156  |
166    | 12     | 76   |), sep="|", header=T)
xx <- read.delim2(textConnection(
Banana | Feijão | Angu |
142    | 175    | 148  |
136    | 177    | 156  |
166    | 12     | 76   |
), sep="|", header=T)
xx <- read.delim2(textConnection(
Banana | Feijão | Angu |
142    | 175    | 148  |
136    | 177    | 156  |
166    | 12     | 76   |
), sep="|", header=T)
xx <- read.delim2(
textConnection(
Banana | Feijão | Angu |
142    | 175    | 148  |
136    | 177    | 156  |
166    | 12     | 76   |
), sep="|", header=T)
xx <- readLines(
textConnection(
Banana | Feijão | Angu |
142    | 175    | 148  |
136    | 177    | 156  |
166    | 12     | 76   |
))
xx <- readLines(
Banana | Feijão | Angu |
142    | 175    | 148  |
136    | 177    | 156  |
166    | 12     | 76   |
)
search()
library(tibble)
xx <- tribble(
~Banana , ~Feijão, ~Angu,
142     ,     175,   148,
136     ,     177,   156,
166     ,      12,    76   |
)
library(tibble)
xx <- tribble(
~Banana , ~Feijão, ~Angu,
142     ,     175,   148,
136     ,     177,   156,
166     ,      12,    76
)
setwd("C:\\Users\\Marcos\\Documents\\MOOCs\\_EdX\\Data Analysis for Social Scientists\\week 3 - Describing Data")
rm(list=ls())
library(utils)
library(ggplot2)
library(tibble)
library(dplyr)
unzip("Gender_Stats_csv.zip", list=TRUE)
unzip("Gender_Stats_csv.zip", "Gender_StatsData.csv")
unzip("Gender_Stats_csv.zip", files="Gender_StatsData.csv")
dados <- unzip("Gender_Stats_csv.zip", list=TRUE)
setwd("C:\\Users\\Marcos\\Documents\\MOOCs\\_EdX\\Data Analysis for Social Scientists\\week 3 - Describing Data")
rm(list=ls())
library(utils)
library(ggplot2)
library(tibble)
library(dplyr)
dados <- unzip("Gender_Stats_csv.zip", list=TRUE)
dados
View(dados)
dados$Name["Gender_StatsData.csv"]
dados$Name[1]
unzip("Gender_Stats_csv.zip", files=dados$Name[1])
# Gender_StatsData.csv
unzip("Gender_Stats_csv.zip")
# Gender_StatsData.csv
library(readr)
library(readr)
gender_data <- read_csv("Gender_StatsData.csv")
library(readr)
setwd("C:\\Users\\Marcos\\Documents\\MOOCs\\_EdX\\Data Analysis for Social Scientists\\week 3 - Describing Data")
gender_data <- read_csv("Gender_StatsData.csv")
View(gender_data)
apropos(rds)
apropos("rds")
saveRDS(gender_data, file="gender_data.rds")
getwd()
teenager_fr <- filter(gender_data, Indicator.Code == "SP.ADO.TFRT")
names(gender_data)
teenager_fr <- filter(gender_data, `Indicator Name` == "SP.ADO.TFRT")
teenager_fr <- filter(gender_data, `Indicator Code` == "SP.ADO.TFRT")
View(teenager_fr)
gender_data$X63 <- NULL
View(gender_data)
saveRDS(gender_data, file="gender_data.rds")
teenager_fr <- filter(gender_data, `Indicator Code` == "SP.ADO.TFRT")
rm(gender_data)
any(is.na(teenager_fr$`1975`))
any(is.na(teenager_fr$`1975`))
mean(teenager_fr$`1975`)
any(is.na(teenager_fr$`1975`))
mean(teenager_fr$`1975`, na.rm = TRUE)
mean(teenager_fr$`1960`, na.rm = TRUE)
sd(teenager_fr$`1960`, na.rm = TRUE)
mean(teenager_fr$`2000`, na.rm = TRUE)
median(teenager_fr$`2000`, na.rm = TRUE)
shiny::runApp('H:/shiny')
list.files()
install.packages("xaringan")
install.packages("yaml")
df1 <- data.frame(V1=c(5, 10, 7, -99, 1, 6),
V2=c(12, 10, -99, 4, 8, 15),
V3=c(34, -99, 7, 8, 9, 3),
V4=c(5, 12, 13, -99, 15, 7),
V5=c(12, 5, 9, 13, 17, -99))
apply(df1, 2, function(x) ifelse(x == -99, NA, x)) # opção 1
df1 <- data.frame(V1=c(5, 10, 7, -99, 1, 6),
V2=c(12, 10, -99, 4, 8, 15),
V3=c(34, -99, 7, 8, 9, 3),
V4=c(5, 12, 13, -99, 15, 7),
V5=c(12, 5, 9, 13, 17, -99))
apply(df1, 2, ifelse, x == -99, NA, x)
df1 <- data.frame(V1=c(5, 10, 7, -99, 1, 6),
V2=c(12, 10, -99, 4, 8, 15),
V3=c(34, -99, 7, 8, 9, 3),
V4=c(5, 12, 13, -99, 15, 7),
V5=c(12, 5, 9, 13, 17, -99))
apply(df1, 2, ifelse,  == -99, NA, x)
df1 <- data.frame(V1=c(5, 10, 7, -99, 1, 6),
V2=c(12, 10, -99, 4, 8, 15),
V3=c(34, -99, 7, 8, 9, 3),
V4=c(5, 12, 13, -99, 15, 7),
V5=c(12, 5, 9, 13, 17, -99))
apply(df1, 2, ifelse,  , -99, NA, x)
Rcmdr()
crp <- readRDS(file.choose())
View(crp)
crp <- subset(crp, grepl("RJ$", crp$Municipio))
View(crp)
getwd()
saveRDS(crp, file = "dados_crp_DtGer_02-03-2018.rds")
comment(crp)
help("mean")
?summary
sqrt(146)
setwd("C:\\Users\\Marcos\\Dropbox\\1. Cursos ECG\\Estatistica Basica com Uso do Software R\\2_Dados\\RData")
load("rh.RData")
ls()
freq_abs <- table(rh$Estado.Civil, useNA = 'ifany')
freq_rel <- prop.table(freq_abs)
cbind(freq_abs, freq_rel)
freq_abs <- table(rh$Estado.Civil, useNA = 'ifany')
freq_rel <- prop.table(freq_abs)
cbind(freq_abs, freq_rel)
addmargins(cbind(freq_abs, freq_rel), 2)
freq_abs <- table(rh$Estado.Civil, useNA = 'ifany')
freq_rel <- prop.table(freq_abs)
cbind(freq_abs, freq_rel)
addmargins(cbind(freq_abs, freq_rel), 1)
mat <- matrix(c(7, 5, 12, 9, 4, 21,
10, 17, 23, 2, 6, 9), nrow=3)
mat
lista1 <- list(vec1 = c(3, 2, 7),
mat1 = matrix(c("a", "b", "c", "d"), nrow = 2))
lista1
library(devtools)
install_github("bayesball/LearnEDA")
library(LearnEDA)
plot(WWWusage)
plot(smooth(WWWusage,kind="3RSS"))
plot(han(smooth(WWWusage,kind="3RSS")))
lval(rnorm(100))
5 %/% 2
5 / 2
5 / 2
library(ggvis)
install.packages("ggvis")
library(ggvis)
#library(dplyr)
mtcars %>%
ggvis(~wt, ~mpg) %>%
layer_smooths(span = input_slider(0.5, 1, value = 1)) %>%
layer_points(size := input_slider(100, 1000, value = 100))
ggvis(mtcars, x = ~wt, y = ~mpg) %>% layer_points()
table(mtcars$cyl)
sort(table(mtcars$cyl))
sort(-table(mtcars$cyl))
-sort(table(mtcars$cyl))
sort(table(mtcars$cyl), decreasing = T)
install.packages("tinytex")
tinytex::install_tinytex()
load(file.choose())
View(medicamentos)
load(file.choose())
with(rh, sort(table(Estado.Civil)))
with(rh, sort(table(rh$Estado.Civil)))
sort(table(rh$Estado.Civil))
## Gráfico de barras
estciv <- sort(table(rh$Estado.Civil))
bp <- barplot(estciv, main='Estado Civil', col=6,
ylim=c(0, max(estciv) + 500))
text(bp, estciv, labels = as.character(estciv), cex=0.7, pos=3)
## Gráfico de barras
estciv <- sort(table(rh$Estado.Civil), decreasing = TRUE)
bp <- barplot(estciv, main='Estado Civil', col=6,
ylim=c(0, max(estciv) + 500))
text(bp, estciv, labels = as.character(estciv), cex=0.7, pos=3)
load(file.choose())
View(estupro)
stripchart(medicamentos$Tempo, method='stack',
at=0, pch=16, col='blue',cex=1.5)
dotchart(medicamentos$Tempo)
stripchart(medicamentos$Tempo, method='stack',
at=0, pch=16, col='blue',cex=1.5)
par(bty="n")
stripchart(medicamentos$Tempo, method='stack',
at=0, pch=16, col='blue',cex=1.5)
dotchart(medicamentos$Tempo)
library(shiny); runApp('G:/lula-app/lula-app.R')
library(shiny); source('G:/butuca.R')
source('G:/butuca.R')
exemplo <- data.frame(tlote = c(30, 20, 60, 80, 40, 50, 60, 30, 70, 60),
hh    = c(73, 50, 128, 170, 87, 108, 135, 69, 148, 132))
modelo <- lm(hh ~ tlote, data=exemplo)
plot(modelo)
resid(modelo)
resid(modelo)
fitted(modelo)
exemplo <- data.frame(tlote = c(30, 20, 60, 80, 40, 50, 60, 30, 70, 60),
hh    = c(73, 50, 128, 170, 87, 108, 135, 69, 148, 132))
modelo <- lm(hh ~ tlote, data=exemplo)
modelo
predict(modelo, data.frame(tlote = 55), level=0.95)
#predict(model, data.frame(pred = new pred), level = 0.95, interval = “confidence”)
predict(modelo, data.frame(tlote = 55), level=0.95, interval = “confidence”)
predict(modelo, data.frame(tlote = 55), level=0.95, interval ='confidence')
#predict(model, data.frame(pred = new pred), level = 0.95, interval = “confidence”)
predict(modelo, data.frame(tlote = 55), level=0.95, interval ='confidence')
confint(modelo, level=0.95)
influence(modelo)
radiant:::radiant_viewer()
radiant:::radiant()
install.packages("DMwR2")
library(DMwR2)
data("sales")
head(sales)
View(sales)
setwd("C:\\Users\\Marcos\\Dropbox\\1. Cursos ECG\\Análise de Dados para Detecção de Fraudes\\___Curso Anache\\Curso ECG - Detecção de Fraudes\\estudos de caso\\lei de benford")
library(readxl)
arena <- read_excel("Testes Arena Amazônia.xlsx", range="A1:F1725", sheet="valores unitários")
str(arena)
summary(arena$`PREÇO TOTAL`)
str(arena)
summary(arena$`PREÇO TOTAL`)
library(benford.analysis)
# Teste dos dois primeiros dígitos
arena.bf <- benford(arena$`PREÇO TOTAL`,
number.of.digits = 2,
sign = "positive",
discrete=TRUE,
round=3)
plot(arena.bf)
summary(arena.bf)
arena.bf
plot(arena.bf)
getSuspects(arena.bf)
getSuspects(arena.bf, arena)
arena.bf$data
library(benford.analysis)
# Teste dos dois primeiros dígitos
arena.bf <- benford(arena$`PREÇO TOTAL`,
number.of.digits = 1,
sign = "positive",
discrete=TRUE,
round=3)
plot(arena.bf)
arena.bf
#
# 1o Laboratóirio de Boas Práticas de Controle Externo
#
library(readxl)
setwd("I:\\Melhores Praticas TCE e Atricon\\ATRICON\\3. Parte Pratica - Laboratorio\\1-capturar dados crp")
source("crpGeraBase.R")
rpps <- read_excel("RELACAO_DOS_ENTES_COM_RPPS.xlsx")
View(rpps)
rpps$CNPJ[1:10]
#
# 1o Laboratóirio de Boas Práticas de Controle Externo
#
options(scipen = 10)
rpps <- read_excel("RELACAO_DOS_ENTES_COM_RPPS.xlsx")
rpps$CNPJ[1:10]
rpps <- read_excel("RELACAO_DOS_ENTES_COM_RPPS.xlsx")
rpps$CNPJ <- ifelse(nchar(rpps$CNPJ) < 14, sprintf("%014.0f",rpps$CNPJ), rpps$CNPJ)
View(rpps)
## Obter o CRP dos RPPS do estado de Alagoas
rppsAL <- subset(rpps, UF == "AL")
View(rppsAL)
# Obtem a base de CRP
dados <- crp_captura_dados(cnpj=rppsAL$CNPJ)
View(dados)
niveis <- c('VENCIDO A MAIS DE 1 ANO',
' VENCIDO ENTRE 181 E 365 DIAS',
'VENCIDO A ATÉ 180 DIAS',
'A VENCER EM 30 DIAS',
'A VENCER ENTRE 31 E 60 DIAS',
'A VENCER ENTRE 61 E 90 DIAS',
'A VENCER ENTRE 91 E 180 DIAS',
'A VENCER A MAIS DE 180')
# Estratificação  (criar uma função????)
dados$DtEmissao  <- as.Date(dados$DtEmissao,  '%d/%m/%Y')
dados$DtValidade <- as.Date(dados$DtValidade, '%d/%m/%Y')
dados$dias <- as.numeric(dados$DtValidade - as.Date(Sys.time()))
dados$faixas <- cut(dados$dias,
breaks=c(-Inf, -366, -181, 0, 30, 60, 90, 180, +Inf),
labels=niveis)
# Ordenar os fatores
dados$faixas <- ordered(dados$faixas, levels=niveis)
library(dplyr)
dados <- arrange(dados, dias)
View(dados)
# Salvar os dados
saveRDS(dados, file=paste("dadosAL_DtGer_", gsub("/", "-", comment(dados)) ,".rds", sep=""))
setwd("I:\\Melhores Praticas TCE e Atricon\\ATRICON\\3. Parte Pratica - Laboratorio\\4-planilha-controle-entregas-xml")
Sys.setenv("RSTUDIO_PANDOC" = "C:/pandoc-2.1.1")
rmarkdown::render("flexDashboard_ControleXML_TabSet.Rmd",
encoding = "utf-8",
output_file = paste("ControleXML", Sys.Date(), ".html", sep = ""))
View(dados)
library(dplyr)
tab <- dados %>%
group_by(faixas) %>%
summarize(Qtd_RPPS = n())
tab
View(dados)
library(ggplot2)
ggplot(tab, aes(x=faixas, y=Qtd_RPPS)) +
geom_bar(stat='identity', fill='lightgreen') +
coord_flip()
